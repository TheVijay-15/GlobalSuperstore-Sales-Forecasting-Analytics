{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1r0MocZUc1leFgQ5MLWUe9dmyiHmHRexc",
      "authorship_tag": "ABX9TyNMa/pZwK3ewQk4/t4pV7E5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheVijay-15/GlobalSuperstore-Sales-Forecasting-Analytics/blob/main/02_data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing & Feature Engineering\n",
        "## Goals:\n",
        "## 1. Handle missing values\n",
        "## 2. Create new features for ML models\n",
        "## 3. Prepare data for time series forecasting"
      ],
      "metadata": {
        "id": "-TXKBquL_Rx4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3u6N9IN9hB9"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the initial cleaned data\n",
        "df = pd.read_csv('/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/initial_cleaned.csv')"
      ],
      "metadata": {
        "id": "xozda9X2Cs-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Handle Missing Values\n",
        "print(\"Handling missing values...\")\n",
        "\n",
        "# Postal Code has missing values\n",
        "# Fill with 0 and create a flag\n",
        "df['Postal_Code_Missing'] = df['Postal Code'].isna().astype(int)\n",
        "df['Postal Code'].fillna(0, inplace=True)\n",
        "\n",
        "# Check if any other missing values remain\n",
        "print(f\"Missing values after handling: {df.isnull().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qExEBJa3DUlk",
        "outputId": "9ea252b6-eed7-4a6f-ae39-c13117fa6f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handling missing values...\n",
            "Missing values after handling: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The current approach of filling with 0 (and creating a Postal_Code_Missing flag) is a common and often effective way to handle missing categorical or quasi-numerical identifiers, as it allows the model to learn from the absence of the postal code."
      ],
      "metadata": {
        "id": "4lT3DtDhEurn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create Time-Based Features\n",
        "print(\"\\nCreating time-based features...\")\n",
        "\n",
        "# Ensure date columns are datetime\n",
        "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
        "df['Ship Date'] = pd.to_datetime(df['Ship Date'])\n",
        "\n",
        "# Time difference features\n",
        "df['Shipping_Days'] = (df['Ship Date'] - df['Order Date']).dt.days\n",
        "df['Processing_Time_Category'] = pd.cut(df['Shipping_Days'],\n",
        "                                        bins=[0, 3, 7, 14, 100],\n",
        "                                        labels=['Express (0-3)', 'Fast (4-7)',\n",
        "                                                'Standard (8-14)', 'Slow (15+)'])\n",
        "\n",
        "# Cyclical time features for seasonality\n",
        "df['Order_Month_Sin'] = np.sin(2 * np.pi * df['Order Date'].dt.month/12)\n",
        "df['Order_Month_Cos'] = np.cos(2 * np.pi * df['Order Date'].dt.month/12)\n",
        "df['Order_Day_Sin'] = np.sin(2 * np.pi * df['Order Date'].dt.day/31)\n",
        "df['Order_Day_Cos'] = np.cos(2 * np.pi * df['Order Date'].dt.day/31)\n",
        "\n",
        "# Holiday periods\n",
        "df['Is_Holiday_Season'] = df['Order Date'].dt.month.isin([11, 12]).astype(int)\n",
        "df['Is_EndOfQuarter'] = df['Order Date'].dt.month.isin([3, 6, 9, 12]).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnKpqEoeDrRm",
        "outputId": "5026fd5b-4f5e-4607-ae4c-924e9808e8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating time-based features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create Business Metrics Features\n",
        "print(\"\\nCreating business metrics features...\")\n",
        "\n",
        "# Profitability indicators\n",
        "df['Profit_Margin'] = (df['Profit'] / df['Sales']).replace([np.inf, -np.inf], 0) * 100\n",
        "df['Is_Profitable'] = (df['Profit'] > 0).astype(int)\n",
        "df['Profit_Per_Unit'] = df['Profit'] / df['Quantity'].replace(0, 1)\n",
        "\n",
        "# Efficiency metrics\n",
        "df['Sales_per_Shipping_Cost'] = df['Sales'] / df['Shipping Cost'].replace(0, 1)\n",
        "df['Discount_Effectiveness'] = (df['Sales'] * df['Discount']) / df['Profit'].replace(0, 1)\n",
        "\n",
        "# Customer value metrics (will be aggregated later)\n",
        "df['Unit_Price'] = df['Sales'] / df['Quantity'].replace(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQJVKv0HE6xy",
        "outputId": "f11664df-5d7a-4b8c-947a-85174470780a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating business metrics features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Categorical Feature Encoding\n",
        "print(\"\\nEncoding categorical features...\")\n",
        "\n",
        "# Label encoding for ordinal categories\n",
        "le = LabelEncoder()\n",
        "categorical_cols = ['Ship Mode', 'Segment', 'Category', 'Sub-Category',\n",
        "                    'Region', 'Market', 'Country']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if col in df.columns:\n",
        "        df[f'{col}_Encoded'] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "# One-hot encoding for important categoricals (limited to avoid curse of dimensionality)\n",
        "# Exclude 'Segment' from one-hot encoding here to preserve the original column for later aggregations\n",
        "df = pd.get_dummies(df, columns=['Ship Mode', 'Region'],\n",
        "                    prefix=['Ship', 'Region'], drop_first=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5UeILBiFB60",
        "outputId": "b2ae6cfc-8362-4dfc-cfa4-3f4bf34efe6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Encoding categorical features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Create Aggregated Customer Features\n",
        "\n",
        "print(\"\\nCreating customer-level features...\")\n",
        "\n",
        "customer_features = df.groupby('Customer ID').agg({\n",
        "    'Sales': ['sum', 'mean', 'count', 'std'],\n",
        "    'Profit': ['sum', 'mean'],\n",
        "    'Order ID': 'nunique',\n",
        "    'Order Date': ['min', 'max']\n",
        "}).round(2)\n",
        "\n",
        "customer_features.columns = ['_'.join(col).strip() for col in customer_features.columns.values]\n",
        "customer_features = customer_features.rename(columns={\n",
        "    'Sales_sum': 'Customer_Total_Sales',\n",
        "    'Sales_mean': 'Customer_Avg_Sale',\n",
        "    'Sales_count': 'Customer_Transaction_Count',\n",
        "    'Sales_std': 'Customer_Sales_Std',\n",
        "    'Profit_sum': 'Customer_Total_Profit',\n",
        "    'Profit_mean': 'Customer_Avg_Profit',\n",
        "    'Order ID_nunique': 'Customer_Order_Count',\n",
        "    'Order Date_min': 'Customer_First_Order',\n",
        "    'Order Date_max': 'Customer_Last_Order'\n",
        "})\n",
        "\n",
        "# Calculate recency, frequency, monetary (RFM) values\n",
        "customer_features['Customer_Recency'] = (pd.Timestamp('2015-01-01') -\n",
        "                                         customer_features['Customer_Last_Order']).dt.days\n",
        "customer_features['Customer_Frequency'] = customer_features['Customer_Order_Count']\n",
        "customer_features['Customer_Monetary'] = customer_features['Customer_Total_Sales']\n",
        "customer_features['Customer_Lifetime'] = (customer_features['Customer_Last_Order'] -\n",
        "                                          customer_features['Customer_First_Order']).dt.days\n",
        "\n",
        "# Merge back to main dataframe\n",
        "df = df.merge(customer_features, on='Customer ID', how='left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2DbPwfIFH2k",
        "outputId": "dc956966-2c06-4959-9b22-cba9a9637177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating customer-level features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Create Product Features\n",
        "print(\"\\nCreating product-level features...\")\n",
        "\n",
        "product_features = df.groupby('Product ID').agg({\n",
        "    'Sales': ['sum', 'mean', 'count', 'std'],\n",
        "    'Profit': ['sum', 'mean'],\n",
        "    'Quantity': ['sum', 'mean'],\n",
        "    'Discount': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "product_features.columns = ['_'.join(col).strip() for col in product_features.columns.values]\n",
        "product_features = product_features.rename(columns={\n",
        "    'Sales_sum': 'Product_Total_Sales',\n",
        "    'Sales_mean': 'Product_Avg_Sale',\n",
        "    'Sales_count': 'Product_Transaction_Count',\n",
        "    'Sales_std': 'Product_Sales_Std',\n",
        "    'Profit_sum': 'Product_Total_Profit',\n",
        "    'Profit_mean': 'Product_Avg_Profit',\n",
        "    'Quantity_sum': 'Product_Total_Quantity',\n",
        "    'Quantity_mean': 'Product_Avg_Quantity',\n",
        "    'Discount_mean': 'Product_Avg_Discount'\n",
        "})\n",
        "\n",
        "# Product popularity and profitability scores\n",
        "product_features['Product_Popularity_Score'] = (\n",
        "    product_features['Product_Transaction_Count'] /\n",
        "    product_features['Product_Transaction_Count'].max() * 100\n",
        ")\n",
        "product_features['Product_Profitability_Score'] = (\n",
        "    product_features['Product_Avg_Profit'] /\n",
        "    product_features['Product_Avg_Profit'].max() * 100\n",
        ")\n",
        "\n",
        "# Merge back to main dataframe\n",
        "df = df.merge(product_features, on='Product ID', how='left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO98sRW7FPGu",
        "outputId": "ae9b5c84-76e8-4fbc-a541-3dfe72630ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating product-level features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Create Regional Features\n",
        "print(\"\\nCreating regional features...\")\n",
        "\n",
        "regional_features = df.groupby('Country').agg({\n",
        "    'Sales': ['sum', 'mean', 'count'],\n",
        "    'Profit': ['sum', 'mean'],\n",
        "    'Customer ID': 'nunique'\n",
        "}).round(2)\n",
        "\n",
        "regional_features.columns = ['_'.join(col).strip() for col in regional_features.columns.values]\n",
        "regional_features = regional_features.rename(columns={\n",
        "    'Sales_sum': 'Country_Total_Sales',\n",
        "    'Sales_mean': 'Country_Avg_Sale',\n",
        "    'Sales_count': 'Country_Transaction_Count',\n",
        "    'Profit_sum': 'Country_Total_Profit',\n",
        "    'Profit_mean': 'Country_Avg_Profit',\n",
        "    'Customer ID_nunique': 'Country_Unique_Customers'\n",
        "})\n",
        "\n",
        "regional_features['Country_Market_Share'] = (\n",
        "    regional_features['Country_Total_Sales'] /\n",
        "    regional_features['Country_Total_Sales'].sum() * 100\n",
        ")\n",
        "regional_features['Country_Profit_Margin'] = (\n",
        "    regional_features['Country_Total_Profit'] /\n",
        "    regional_features['Country_Total_Sales'] * 100\n",
        ")\n",
        "\n",
        "# Merge back to main dataframe\n",
        "df = df.merge(regional_features, on='Country', how='left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXXHwg90FfHv",
        "outputId": "5f6dd05a-b340-45d0-b419-f2214485c98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating regional features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Feature Scaling\n",
        "print(\"\\nScaling numerical features...\")\n",
        "\n",
        "# Identify numerical columns (excluding ID columns and dates)\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "exclude_from_scaling = ['Row ID', 'Postal Code', 'Postal_Code_Missing',\n",
        "                        'Is_Profitable', 'Is_Holiday_Season', 'Is_EndOfQuarter']\n",
        "exclude_from_scaling += [col for col in df.columns if 'Encoded' in col or '_dummy' in col.lower()]\n",
        "\n",
        "scaling_cols = [col for col in numerical_cols if col not in exclude_from_scaling]\n",
        "\n",
        "# Use MinMaxScaler for better interpretability\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = df.copy()\n",
        "df_scaled[scaling_cols] = scaler.fit_transform(df[scaling_cols])\n",
        "\n",
        "# Save the scaler for future use\n",
        "import joblib\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/scaler.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8RuybCmFwu3",
        "outputId": "b04fcfb3-5a7c-4141-ebca-e90e1f3cb874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Scaling numerical features...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Save Processed Data\n",
        "print(\"\\nSaving processed data...\")\n",
        "\n",
        "# Save full processed dataset\n",
        "df_scaled.to_csv('/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/fully_processed.csv', index=False)\n",
        "\n",
        "# Create aggregated datasets for different analyses\n",
        "# Daily sales for time series forecasting\n",
        "daily_sales = df.groupby('Order Date').agg({\n",
        "    'Sales': 'sum',\n",
        "    'Profit': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'Order ID': 'nunique'\n",
        "}).reset_index()\n",
        "daily_sales.columns = ['Date', 'Daily_Sales', 'Daily_Profit', 'Daily_Quantity', 'Daily_Orders']\n",
        "daily_sales.to_csv('/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/daily_sales_agg.csv', index=False)\n",
        "\n",
        "# Monthly sales by category\n",
        "monthly_category = df.groupby([pd.Grouper(key='Order Date', freq='M'), 'Category']).agg({\n",
        "    'Sales': 'sum',\n",
        "    'Profit': 'sum',\n",
        "    'Quantity': 'sum'\n",
        "}).reset_index()\n",
        "monthly_category.to_csv('/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/monthly_category.csv', index=False)\n",
        "\n",
        "# Customer-level dataset for segmentation\n",
        "customer_dataset = df.groupby('Customer ID').agg({\n",
        "    'Customer_Recency': 'first',\n",
        "    'Customer_Frequency': 'first',\n",
        "    'Customer_Monetary': 'first',\n",
        "    'Customer_Lifetime': 'first',\n",
        "    'Customer_Total_Profit': 'first',\n",
        "    'Country': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Unknown',\n",
        "    'Segment': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Unknown'\n",
        "}).reset_index()\n",
        "customer_dataset.to_csv('/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/customer_segmentation.csv', index=False)\n",
        "\n",
        "print(\"Processing complete! Files saved:\")\n",
        "print(\"/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/fully_processed.csv\")\n",
        "print(\"/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/daily_sales_agg.csv\")\n",
        "print(\"/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/monthly_category.csv\")\n",
        "print(\"/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/customer_segmentation.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV2-44QkHEvz",
        "outputId": "88c15436-8bda-4456-bdb4-4977437e3e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving processed data...\n",
            "Processing complete! Files saved:\n",
            "/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/fully_processed.csv\n",
            "/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/daily_sales_agg.csv\n",
            "/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/monthly_category.csv\n",
            "/content/drive/MyDrive/GlobalSuperstore_Project/data/processed/customer_segmentation.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFeature correlation with Profit:\")\n",
        "profit_corr = df.select_dtypes(include=np.number).corr()['Profit'].sort_values(ascending=False)\n",
        "print(\"\\nTop 10 Positive Correlations with Profit:\")\n",
        "print(profit_corr.head(10))\n",
        "print(\"\\nTop 10 Negative Correlations with Profit:\")\n",
        "print(profit_corr.tail(10))"
      ],
      "metadata": {
        "id": "SLL-hVuTL-4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17a9991-e6d8-4c70-8f05-9a7a60f6ffb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature correlation with Profit:\n",
            "\n",
            "Top 10 Positive Correlations with Profit:\n",
            "Profit                         1.000000\n",
            "Profit_Per_Unit                0.838825\n",
            "Product_Avg_Profit             0.708139\n",
            "Product_Profitability_Score    0.708139\n",
            "Product_Total_Profit           0.604566\n",
            "Sales                          0.484918\n",
            "Unit_Price                     0.418647\n",
            "Profit_Margin                  0.358106\n",
            "Shipping Cost                  0.354441\n",
            "Is_Profitable                  0.332106\n",
            "Name: Profit, dtype: float64\n",
            "\n",
            "Top 10 Negative Correlations with Profit:\n",
            "Postal Code                 -0.009549\n",
            "Product_Transaction_Count   -0.015632\n",
            "Product_Popularity_Score    -0.015632\n",
            "Market_Encoded              -0.017308\n",
            "Row ID                      -0.019037\n",
            "Customer_Recency            -0.025790\n",
            "Sub-Category_Encoded        -0.040321\n",
            "Country_Encoded             -0.053919\n",
            "Product_Avg_Discount        -0.186730\n",
            "Discount                    -0.316490\n",
            "Name: Profit, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}